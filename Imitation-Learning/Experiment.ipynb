{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import torch\n",
                "from typing import Any\n",
                "import numpy as np\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from Traj2Dataset import TrajDataset,DatasetTransform\n",
                "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning import loggers\n",
                "from pytorch_lightning.callbacks import EarlyStopping\n",
                "from pytorch_lightning import seed_everything\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "class Net(nn.Module):\n",
                "    def __init__(self, in_dims, out_dims):\n",
                "        super(Net, self).__init__()\n",
                "        self.layers = nn.Sequential(\n",
                "            nn.Linear(in_dims, 16),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(16, 16),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(16, out_dims)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.layers(x)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "class LitMLP(pl.LightningModule):\n",
                "    def __init__(\n",
                "        self,\n",
                "        in_dims: int,\n",
                "        out_dims: int,\n",
                "        lr: float = 1e-3,\n",
                "        *args: Any,\n",
                "        **kwargs: Any\n",
                "    ) -> None:\n",
                "        super().__init__(*args, **kwargs)\n",
                "        \n",
                "        self.model = Net(in_dims, out_dims)\n",
                "        self.lr = lr\n",
                "        \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        return self.model(x)\n",
                "    \n",
                "    def training_step(self,batch,batch_idx):\n",
                "        x,y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log({'loss':loss},logger = True)\n",
                "        return loss\n",
                "\n",
                "    def validation_step(self,batch,batch_idx):\n",
                "        x,y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log('val_loss', loss,logger = True)\n",
                "        return loss\n",
                "\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return torch.optim.Adam(self.model.parameters(),lr = self.lr)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### HYPERPARAMETERS"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "root_dir = 'dataset'\n",
                "system = 'great-piquant-bumblebee'\n",
                "validation_split = 0.2\n",
                "learning_rate = 1e-3\n",
                "batch_size = 32\n",
                "max_epochs = 100\n",
                "shuffle = True\n",
                "SEED = 42\n",
                "logdir = './logs/'\n",
                "num_workers = 4\n",
                "\n",
                "seed_everything(SEED)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### TRAINING AND VALIDATION DATASET PREPARATION"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "dataset = TrajDataset(system, root_dir)\n",
                "\n",
                "state_dim = len(dataset.states)\n",
                "action_dim = len(dataset.actions)\n",
                "\n",
                "mean = [x['mean'] for x in dataset.states]  # mean\n",
                "std = [x['std'] for x in dataset.states]   # std_dev\n",
                "transform = DatasetTransform(mean, std)\n",
                "\n",
                "target_mean = [x['mean'] for x in dataset.actions]  # mean\n",
                "target_std = [x['std'] for x in dataset.actions]   # std_dev\n",
                "target_transform = DatasetTransform(target_mean, target_std)\n",
                "\n",
                "dataset.tranform = transform\n",
                "dataset.target_transform = target_transform\n",
                "\n",
                "\n",
                "indices = np.arange(len(dataset))\n",
                "\n",
                "if shuffle is True:\n",
                "    np.random.shuffle(indices)\n",
                "\n",
                "split = int(validation_split * len(dataset))\n",
                "train_indices = indices[split:]\n",
                "valid_indices = indices[:split]\n",
                "\n",
                "  # may use wandb later\n",
                "train_sampler = SubsetRandomSampler(train_indices)\n",
                "valid_sampler = SubsetRandomSampler(valid_indices)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "callbacks = []\n",
                "\n",
                "tb_logger = loggers.TensorBoardLogger(logdir)\n",
                "\n",
                "train_dataloader = DataLoader(dataset,\n",
                "            batch_size=batch_size,num_workers=num_workers,\n",
                "            sampler=train_sampler)\n",
                "valid_dataloader = DataLoader(dataset,\n",
                "            batch_size=batch_size,num_workers=num_workers,\n",
                "            sampler=valid_sampler)\n",
                "\n",
                "model = LitMLP(state_dim, action_dim,learning_rate)\n",
                "trainer = pl.Trainer(\n",
                "    gpus=1, logger=tb_logger,\n",
                "    callbacks=callbacks,\n",
                "    progress_bar_refresh_rate=10,\n",
                "    max_epochs= max_epochs,)\n",
                "\n",
                "trainer.fit(model, train_dataloader, valid_dataloader)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "x,y = dataset[24]\n",
                "x = torch.Tensor(x)\n",
                "print(model(x),y)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.10 64-bit ('RL': conda)"
        },
        "interpreter": {
            "hash": "15e12cfe0361206d66230a54dc7fb2938cfb5d9b46e860fa44b9fcd523b6b277"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}