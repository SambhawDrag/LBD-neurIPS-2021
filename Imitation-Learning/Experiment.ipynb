{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import torch\n",
                "from typing import Any\n",
                "import numpy as np\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from Traj2Dataset import TrajDataset,DatasetTransform\n",
                "from torch.utils.data import DataLoader,SubsetRandomSampler\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning import loggers\n",
                "from pytorch_lightning.callbacks import EarlyStopping\n",
                "from pytorch_lightning import seed_everything\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "source": [
                "class Net(nn.Module):\n",
                "    def __init__(self, in_dims, out_dims):\n",
                "        super(Net, self).__init__()\n",
                "        self.layers = nn.Sequential(\n",
                "            nn.Linear(in_dims,16),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(16,16),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(16, out_dims)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.layers(x)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "class LitMLP(pl.LightningModule):\n",
                "    def __init__(\n",
                "        self,\n",
                "        in_dims: int,\n",
                "        out_dims: int,\n",
                "        lr: float = 1e-3,\n",
                "        *args: Any,\n",
                "        **kwargs: Any\n",
                "    ) -> None:\n",
                "        super().__init__(*args, **kwargs)\n",
                "        \n",
                "        self.model = Net(in_dims, out_dims)\n",
                "        self.lr = lr\n",
                "        \n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        return self.model(x)\n",
                "    \n",
                "    def training_step(self,batch,batch_idx):\n",
                "        x,y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log('train_loss',loss,logger = True)\n",
                "        return loss\n",
                "\n",
                "    def validation_step(self,batch,batch_idx):\n",
                "        x,y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log('val_loss', loss,logger = True)\n",
                "        return loss\n",
                "\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return torch.optim.Adam(self.model.parameters(),lr = self.lr)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### HYPERPARAMETERS"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "root_dir = 'dataset'\n",
                "system = 'great-piquant-bumblebee'\n",
                "validation_split = 0.2\n",
                "learning_rate = 1e-3\n",
                "batch_size = 32\n",
                "max_epochs = 100\n",
                "shuffle = True\n",
                "SEED = 42\n",
                "logdir = './logs/'\n",
                "num_workers = 4\n",
                "\n",
                "seed_everything(SEED)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "42"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### TRAINING AND VALIDATION DATASET PREPARATION"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "dataset = TrajDataset(system, root_dir)\n",
                "\n",
                "state_dim = len(dataset.states)\n",
                "action_dim = len(dataset.actions)\n",
                "\n",
                "mean = [x['mean'] for x in dataset.states]  # mean\n",
                "std = [x['std'] for x in dataset.states]   # std_dev\n",
                "transform = DatasetTransform(mean, std)\n",
                "\n",
                "target_mean = [x['mean'] for x in dataset.actions]  # mean\n",
                "target_std = [x['std'] for x in dataset.actions]   # std_dev\n",
                "target_transform = DatasetTransform(target_mean, target_std)\n",
                "\n",
                "dataset.tranform = transform\n",
                "dataset.target_transform = target_transform\n",
                "\n",
                "\n",
                "indices = np.arange(len(dataset))\n",
                "\n",
                "if shuffle is True:\n",
                "    np.random.shuffle(indices)\n",
                "\n",
                "split = int(validation_split * len(dataset))\n",
                "train_indices = indices[split:]\n",
                "valid_indices = indices[:split]\n",
                "\n",
                "  # may use wandb later\n",
                "train_sampler = SubsetRandomSampler(train_indices)\n",
                "valid_sampler = SubsetRandomSampler(valid_indices)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "callbacks = []\n",
                "\n",
                "tb_logger = loggers.TensorBoardLogger(logdir)\n",
                "\n",
                "train_dataloader = DataLoader(dataset,\n",
                "            batch_size=batch_size,num_workers=num_workers,\n",
                "            sampler=train_sampler)\n",
                "valid_dataloader = DataLoader(dataset,\n",
                "            batch_size=batch_size,num_workers=num_workers,\n",
                "            sampler=valid_sampler)\n",
                "\n",
                "model = LitMLP(state_dim, action_dim,learning_rate)\n",
                "trainer = pl.Trainer(\n",
                "    gpus=1, logger=tb_logger,\n",
                "    callbacks=callbacks,\n",
                "    progress_bar_refresh_rate=60,\n",
                "    max_epochs= max_epochs,)\n",
                "\n",
                "trainer.fit(model, train_dataloader, valid_dataloader)\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "GPU available: True, used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
                        "\n",
                        "  | Name  | Type | Params\n",
                        "-------------------------------\n",
                        "0 | model | Net  | 482   \n",
                        "-------------------------------\n",
                        "482       Trainable params\n",
                        "0         Non-trainable params\n",
                        "482       Total params\n",
                        "0.002     Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "                                                              "
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "Global seed set to 42\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Epoch 99: 100%|██████████| 125/125 [00:01<00:00, 90.70it/s, loss=2.31, v_num=11]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "x,y = dataset[0]\n",
                "x = torch.Tensor(x)\n",
                "print(model(x),y)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([-5.6737,  3.7289], grad_fn=<AddBackward0>) [-21.243172  15.410698]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "source": [
                "model_checkpoint = LitMLP.load_from_checkpoint(\"./logs/default/version_11/checkpoints/epoch=99-step=9999.ckpt\",\n",
                "                                               in_dims=10, out_dims=2, lr=1e-3)\n",
                "model_checkpoint.eval()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "source": [
                "print(x,model(x),y)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "tensor([ 1.2797, -0.9566,  0.0000, -0.9566, -4.0413,  4.0828,  0.0000,  4.0828,\n",
                        "         1.2387, -0.9151]) tensor([-4.9117,  4.6574], grad_fn=<AddBackward0>) [-3.8265183  4.1371217]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.10 64-bit ('RL': conda)"
        },
        "interpreter": {
            "hash": "15e12cfe0361206d66230a54dc7fb2938cfb5d9b46e860fa44b9fcd523b6b277"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}