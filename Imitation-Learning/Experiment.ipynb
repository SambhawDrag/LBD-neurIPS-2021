{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "### Notebook for experimenting with model architecture and hparams\n",
                "Github repository link: [SambhawDrag/LBD-neurIPS-2021](https://github.com/SambhawDrag/LBD-neurIPS-2021)"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import torch\n",
                "from typing import Any\n",
                "import numpy as np\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from Traj2Dataset import TrajDataset, DatasetTransform\n",
                "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
                "import pytorch_lightning as pl\n",
                "from pytorch_lightning import loggers\n",
                "from pytorch_lightning.callbacks import EarlyStopping\n",
                "from pytorch_lightning import seed_everything"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "class Net(nn.Module):\n",
                "    def __init__(self, in_dims, out_dims):\n",
                "        super(Net, self).__init__()\n",
                "        self.layers = nn.Sequential(\n",
                "            nn.Linear(in_dims,16),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(16,32),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(32,64),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(64,32),\n",
                "            nn.ReLU(),\n",
                "            nn.Linear(32,out_dims),\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.layers(x)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "class LitMLP(pl.LightningModule):\n",
                "    def __init__(\n",
                "        self,\n",
                "        in_dims: int,\n",
                "        out_dims: int,\n",
                "        lr: float = 1e-3,\n",
                "        *args: Any,\n",
                "        **kwargs: Any\n",
                "    ) -> None:\n",
                "        super().__init__(*args, **kwargs)\n",
                "\n",
                "        self.model = Net(in_dims, out_dims)\n",
                "        self.lr = lr\n",
                "\n",
                "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
                "        return self.model(x)\n",
                "\n",
                "    def training_step(self, batch, batch_idx):\n",
                "        x, y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log('train_loss', loss, logger=True)\n",
                "        return loss\n",
                "\n",
                "    def validation_step(self, batch, batch_idx):\n",
                "        x, y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log('val_loss', loss, logger=True)\n",
                "        return loss\n",
                "\n",
                "    def test_step(self, batch, batch_idx):\n",
                "        x, y = batch\n",
                "        y_hat = self.forward(x)\n",
                "        loss = F.mse_loss(y_hat, y)\n",
                "        self.log('test_loss', loss, logger=True)\n",
                "        return loss\n",
                "\n",
                "    def configure_optimizers(self):\n",
                "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### HYPERPARAMETERS"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "root_dir = 'dataset'\n",
                "system = 'great-wine-beetle'\n",
                "validation_split = 0.2\n",
                "learning_rate = 5e-4\n",
                "batch_size = 256\n",
                "max_epochs = 200\n",
                "shuffle = True\n",
                "SEED = 42\n",
                "logdir = './logs/'\n",
                "num_workers = 4\n",
                "\n",
                "seed_everything(SEED)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "class TargetCentreTransform():\n",
                "    def __init__(self):\n",
                "        pass\n",
                "    def __call__(self, x: np.ndarray) -> np.ndarray:\n",
                "        x[-2:] -= x[:2]\n",
                "        return x"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "### TRAINING AND VALIDATION DATASET PREPARATION"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "state_norms, action_norms = TrajDataset.norms(system)\n",
                "\n",
                "state_dim = len(state_norms)\n",
                "action_dim = len(action_norms)\n",
                "\n",
                "mean = state_norms[:, 0]  # mean\n",
                "std = state_norms[:, 1]  # std_dev\n",
                "transform = DatasetTransform(mean, std)\n",
                "\n",
                "target_mean = action_norms[:, 0]  # mean\n",
                "target_std = action_norms[:, 1]  # std_dev\n",
                "target_transform = DatasetTransform(target_mean, target_std)\n",
                "\n",
                "train_dataset = TrajDataset(system, root_dir, train=True,\n",
                "                            transform=transform, target_transform=target_transform)\n",
                "\n",
                "test_dataset = TrajDataset(system, root_dir, train=False,\n",
                "                           transform=transform, target_transform=target_transform)\n",
                "indices = np.arange(len(train_dataset))\n",
                "\n",
                "if shuffle is True:\n",
                "    np.random.shuffle(indices)\n",
                "\n",
                "split = int(validation_split * len(train_dataset))\n",
                "train_indices = indices[split:]\n",
                "valid_indices = indices[:split]\n",
                "\n",
                "# may use wandb later\n",
                "train_sampler = SubsetRandomSampler(train_indices)\n",
                "valid_sampler = SubsetRandomSampler(valid_indices)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "callbacks = []\n",
                "\n",
                "tb_logger = loggers.TensorBoardLogger(logdir,name = 'v3')\n",
                "\n",
                "train_dataloader = DataLoader(train_dataset,\n",
                "                              batch_size=batch_size, num_workers=num_workers,\n",
                "                              sampler=train_sampler)\n",
                "valid_dataloader = DataLoader(train_dataset,\n",
                "                              batch_size=batch_size, num_workers=num_workers,\n",
                "                              sampler=valid_sampler)\n",
                "model = LitMLP(state_dim, action_dim, learning_rate)\n",
                "trainer = pl.Trainer(\n",
                "    gpus=1, logger=tb_logger,\n",
                "    callbacks=callbacks,\n",
                "    progress_bar_refresh_rate=60,\n",
                "    max_epochs=max_epochs,)\n",
                "\n",
                "trainer.fit(model, train_dataloader, valid_dataloader)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def upscale(x):\n",
                "    return x * torch.Tensor(target_std) + torch.Tensor(target_mean)\n",
                "\n",
                "test_dataloader = DataLoader(test_dataset,\n",
                "                             batch_size=1, shuffle=False,\n",
                "                             num_workers=0)\n",
                "logs = trainer.test(model,test_dataloader,verbose=False)\n",
                "# print(logs)\n",
                "for i, (x, y) in enumerate(test_dataloader):\n",
                "    print(f'Time-step: {i}')\n",
                "    print(f'Target: {upscale(y)}')\n",
                "    print(f'Prediction: {upscale(model(x))}')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from matplotlib import pyplot as plt\n",
                "\n",
                "targets = []\n",
                "test_dataset = TrajDataset(system,root_dir,train = False)\n",
                "print(test_dataset.states)\n",
                "\n",
                "# first two states are X,Y for end-effectors\n",
                "for i,(x,_) in enumerate(test_dataset):\n",
                "    targets.append(x[0:2])\n",
                "targets = np.array(targets)\n",
                "plt.plot(targets[:,0],targets[:,1])"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "targets = []\n",
                "train_dataset = TrajDataset(system, root_dir, train=True)\n",
                "\n",
                "# first two states are X,Y for end-effectors\n",
                "traj_ID = 3\n",
                "for i, (x, _) in enumerate(train_dataset):\n",
                "    # each trajectory is a slice of 200 points in dataset\n",
                "    if i in range(200*traj_ID, 200*(traj_ID+1)):\n",
                "        targets.append(x[:2])\n",
                "targets = np.array(targets)\n",
                "plt.plot(targets[:, 0], targets[:, 1])"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7.10 64-bit ('RL': conda)"
        },
        "interpreter": {
            "hash": "15e12cfe0361206d66230a54dc7fb2938cfb5d9b46e860fa44b9fcd523b6b277"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}